#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenChemIE åŒ–å­¦ä¿¡æ¯æå–å·¥å…· v2.0
é‡‡ç”¨ä¼˜åŒ–çš„JSONè¾“å‡ºç»“æ„ï¼Œæ›´æ¸…æ™°ã€æ›´æœ‰æ¡ç†
"""

import torch
from openchemie import OpenChemIE
import os
import json
import argparse
import cv2
import glob
import time
import psutil
from datetime import datetime
from pathlib import Path
import sys
from rdkit import Chem
from rdkit.Chem import Descriptors, Crippen


class OpenChemIEExtractorV2:
    def __init__(self, device=None, verbose=True):
        """
        åˆå§‹åŒ–æå–å™¨ v2.0
        
        Args:
            device: è®¡ç®—è®¾å¤‡ ('cuda', 'cpu' æˆ– None è‡ªåŠ¨é€‰æ‹©)
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
        self.verbose = verbose
        self.schema_version = "2.0.0"
        self.extractor_version = "2.0.0"
        
        # è®¾ç½®è®¾å¤‡
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        if self.verbose:
            print(f"ğŸš€ OpenChemIEæå–å™¨ v{self.extractor_version} åˆå§‹åŒ–")
            print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        try:
            self.model = OpenChemIE(device=self.device)
            if self.verbose:
                print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def extract_from_pdf(self, pdf_path, output_images=False, output_bbox=True, extract_corefs=True):
        """
        ä»PDFæ–‡ä»¶ä¸­æå–åŒ–å­¦ä¿¡æ¯ - æ–°ç‰ˆæœ¬ç»“æ„
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            output_images: æ˜¯å¦è¾“å‡ºæå–çš„å›¾ç‰‡
            output_bbox: æ˜¯å¦è¾“å‡ºè¾¹ç•Œæ¡†ä¿¡æ¯
            extract_corefs: æ˜¯å¦æå–åˆ†å­å…±æŒ‡å…³ç³»
            
        Returns:
            dict: ä¼˜åŒ–ç»“æ„çš„æå–ç»“æœ
        """
        start_time = time.time()
        
        if self.verbose:
            print(f"\nğŸ” å¼€å§‹å¤„ç†PDF: {pdf_path}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_info = self._get_file_info(pdf_path)
        
        # åˆå§‹åŒ–ç»“æœç»“æ„
        results = self._initialize_result_structure(pdf_path, file_info, {
            "output_images": output_images,
            "output_bbox": output_bbox,
            "extract_corefs": extract_corefs,
            "device": str(self.device)
        })
        
        try:
            # æå–åˆ†å­
            if self.verbose:
                print("ğŸ§ª æå–åˆ†å­...")
            molecules_data = self._extract_molecules_from_pdf(pdf_path, output_bbox, output_images)
            
            # æå–ååº”
            if self.verbose:
                print("âš—ï¸ æå–ååº”...")
            reactions_data = self._extract_reactions_from_pdf(pdf_path, output_bbox)
            
            # æå–å›¾ç‰‡
            if self.verbose:
                print("ğŸ–¼ï¸ æå–å›¾ç‰‡...")
            figures_data = self._extract_figures_from_pdf(pdf_path, output_bbox, output_images)
            
            # æå–è¡¨æ ¼
            if self.verbose:
                print("ğŸ“Š æå–è¡¨æ ¼...")
            tables_data = self._extract_tables_from_pdf(pdf_path, output_bbox)
            
            # æå–å…±æŒ‡å…³ç³»
            corefs_data = {}
            if extract_corefs:
                if self.verbose:
                    print("ğŸ”— æå–åˆ†å­å…±æŒ‡å…³ç³»...")
                corefs_data = self._extract_coreferences_from_pdf(pdf_path)
            
            # ç»„è£…åŒ–å­¦å®ä½“æ•°æ®
            results["chemical_entities"] = self._build_chemical_entities(molecules_data, reactions_data)
            
            # ç»„è£…æ–‡æ¡£å†…å®¹æ•°æ®
            results["document_content"] = self._build_document_content(figures_data, tables_data)
            
            # ç»„è£…å…³ç³»æ•°æ®
            results["relationships"] = self._build_relationships(corefs_data, molecules_data)
            
            # è®¡ç®—è´¨é‡æŒ‡æ ‡
            results["quality_metrics"] = self._calculate_quality_metrics(molecules_data, reactions_data, tables_data, corefs_data)
            
            # å¤„ç†å®Œæˆ
            end_time = time.time()
            processing_time = end_time - start_time
            
            # æ›´æ–°å¤„ç†ä¿¡æ¯
            results["metadata"]["extraction_info"]["processing_time_seconds"] = round(processing_time, 2)
            results["statistics"] = self._calculate_statistics(results, processing_time)
            
            if self.verbose:
                print(f"âœ… å¤„ç†å®Œæˆï¼è€—æ—¶: {processing_time:.2f}ç§’")
                self._print_summary(results)
            
            return results
            
        except Exception as e:
            if self.verbose:
                print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            raise

    def _get_file_info(self, file_path):
        """è·å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯"""
        file_stat = os.stat(file_path)
        return {
            "size_mb": round(file_stat.st_size / (1024 * 1024), 2),
            "modified_time": datetime.fromtimestamp(file_stat.st_mtime).isoformat()
        }

    def _initialize_result_structure(self, file_path, file_info, config):
        """åˆå§‹åŒ–ç»“æœç»“æ„"""
        return {
            "schema_version": self.schema_version,
            "metadata": {
                "extraction_info": {
                    "timestamp": datetime.now().isoformat(),
                    "extractor_version": self.extractor_version,
                    "device_used": config["device"],
                    "processing_time_seconds": 0
                },
                "document_info": {
                    "file_path": file_path,
                    "file_name": os.path.basename(file_path),
                    "file_type": "pdf",
                    "file_size_mb": file_info["size_mb"],
                    "total_pages": 0,  # å°†åœ¨å¤„ç†è¿‡ç¨‹ä¸­æ›´æ–°
                    "language": "auto_detected"
                },
                "extraction_config": config
            },
            "document_structure": {
                "pages": [],
                "total_figures": 0,
                "total_tables": 0,
                "total_text_blocks": 0
            },
            "chemical_entities": {},
            "document_content": {},
            "relationships": {},
            "quality_metrics": {},
            "statistics": {}
        }

    def _extract_molecules_from_pdf(self, pdf_path, output_bbox, output_images):
        """æå–åˆ†å­ä¿¡æ¯"""
        try:
            # ä»å›¾ç‰‡ä¸­æå–åˆ†å­ - ä¿®æ­£å‚æ•°å
            molecules_from_figures = self.model.extract_molecules_from_figures_in_pdf(pdf_path)
            
            # ä»æ–‡æœ¬ä¸­æå–åˆ†å­  
            molecules_from_text = self.model.extract_molecules_from_text_in_pdf(pdf_path)
            
            return {
                "from_figures": molecules_from_figures,
                "from_text": molecules_from_text
            }
        except Exception as e:
            if self.verbose:
                print(f"âš ï¸ åˆ†å­æå–è­¦å‘Š: {e}")
            return {"from_figures": [], "from_text": []}

    def _extract_reactions_from_pdf(self, pdf_path, output_bbox):
        """æå–ååº”ä¿¡æ¯"""
        try:
            # ä¿®æ­£å‚æ•°å
            reactions = self.model.extract_reactions_from_figures_in_pdf(pdf_path)
            return reactions
        except Exception as e:
            if self.verbose:
                print(f"âš ï¸ ååº”æå–è­¦å‘Š: {e}")
            return []

    def _extract_figures_from_pdf(self, pdf_path, output_bbox, output_images):
        """æå–å›¾ç‰‡ä¿¡æ¯"""
        try:
            # ä¿®æ­£å‚æ•°å
            figures = self.model.extract_figures_from_pdf(
                pdf_path, output_bbox=output_bbox, output_image=output_images
            )
            return figures
        except Exception as e:
            if self.verbose:
                print(f"âš ï¸ å›¾ç‰‡æå–è­¦å‘Š: {e}")
            return []

    def _extract_tables_from_pdf(self, pdf_path, output_bbox):
        """æå–è¡¨æ ¼ä¿¡æ¯"""
        try:
            # ä¿®æ­£å‚æ•°å
            tables = self.model.extract_tables_from_pdf(
                pdf_path, output_bbox=output_bbox
            )
            return tables
        except Exception as e:
            if self.verbose:
                print(f"âš ï¸ è¡¨æ ¼æå–è­¦å‘Š: {e}")
            return []

    def _extract_coreferences_from_pdf(self, pdf_path):
        """æå–å…±æŒ‡å…³ç³»"""
        try:
            corefs = self.model.extract_molecule_corefs_from_figures_in_pdf(pdf_path)
            return corefs
        except Exception as e:
            if self.verbose:
                print(f"âš ï¸ å…±æŒ‡å…³ç³»æå–è­¦å‘Š: {e}")
            return {}

    def _build_chemical_entities(self, molecules_data, reactions_data):
        """æ„å»ºåŒ–å­¦å®ä½“éƒ¨åˆ†"""
        molecule_analysis = self._analyze_molecules(molecules_data)
        reaction_analysis = self._analyze_reactions(reactions_data)
        
        return {
            "molecules": {
                "total_unique_molecules": molecule_analysis["total_unique_molecules"],
                "total_mentions": molecule_analysis["total_mentions"],
                "source_distribution": molecule_analysis["source_distribution"],
                "confidence_metrics": molecule_analysis["confidence_metrics"],
                "property_summary": molecule_analysis["property_summary"],
                "molecule_list": molecule_analysis["molecule_list"]
            },
            "reactions": {
                "total_reactions": reaction_analysis["total_reactions"],
                "reaction_list": reaction_analysis["reaction_list"]
            }
        }
        
    def _analyze_molecules(self, molecules_data):
        """åˆ†æå’Œæ•´åˆåˆ†å­æ•°æ®"""
        all_molecules = []
        
        # åˆå¹¶æ¥è‡ªä¸åŒæ¥æºçš„åˆ†å­
        for mol_list in molecules_data.values():
            all_molecules.extend(mol_list)
        
        # å»é‡å¹¶å¢å¼ºæ•°æ®
        unique_molecules = {}
        molecule_id_counter = 1
        for mol_data in all_molecules:
            smiles = mol_data.get("smiles")
            if not smiles:
                continue
            
            if smiles not in unique_molecules:
                unique_molecules[smiles] = self._enhance_molecule_data(mol_data, f"MOL-{molecule_id_counter}")
                molecule_id_counter += 1
            else:
                # åˆå¹¶æåŠæ¬¡æ•°å’Œæ¥æº
                unique_molecules[smiles]["mentions"].append({
                    "source": mol_data.get("source", "unknown"),
                    "confidence": self._normalize_confidence(mol_data.get("score")),
                    "page": mol_data.get("page_number"),
                    "bbox": mol_data.get("bbox")
                })

        # å‡†å¤‡æœ€ç»ˆè¾“å‡º
        molecule_list = list(unique_molecules.values())
        source_distribution = self._organize_molecules_by_source(molecules_data)
        
        # æå–æ‰€æœ‰ç½®ä¿¡åº¦åˆ†æ•°
        all_confidences = [
            mention["confidence"] for mol in molecule_list for mention in mol["mentions"] if mention["confidence"] is not None
        ]
        
        # æå–æ‰€æœ‰åˆ†å­é‡å’ŒLogP
        all_mw = [mol["properties"]["molecular_weight"] for mol in molecule_list if mol["properties"]["molecular_weight"] is not None]
        all_logp = [mol["properties"]["logP"] for mol in molecule_list if mol["properties"]["logP"] is not None]

        return {
            "total_unique_molecules": len(molecule_list),
            "total_mentions": len(all_molecules),
            "source_distribution": source_distribution,
            "confidence_metrics": self._analyze_confidence_distribution(all_confidences),
            "property_summary": {
                "molecular_weight": {
                    "average": round(np.mean(all_mw), 2) if all_mw else 0,
                    "std_dev": round(np.std(all_mw), 2) if all_mw else 0,
                    "min": min(all_mw) if all_mw else 0,
                    "max": max(all_mw) if all_mw else 0
                },
                "logP": {
                    "average": round(np.mean(all_logp), 2) if all_logp else 0,
                    "std_dev": round(np.std(all_logp), 2) if all_logp else 0,
                    "min": min(all_logp) if all_logp else 0,
                    "max": max(all_logp) if all_logp else 0
                }
            },
            "molecule_list": molecule_list
        }
        
    def _analyze_confidence_distribution(self, scores):
        """è®¡ç®—ç½®ä¿¡åº¦åˆ†å¸ƒ"""
        if not scores:
            return {"average": 0, "std_dev": 0, "min": 0, "max": 0, "distribution_percentiles": {}}
        
        return {
            "average": round(np.mean(scores), 2),
            "std_dev": round(np.std(scores), 2),
            "min": round(min(scores), 2),
            "max": round(max(scores), 2),
            "distribution_percentiles": {
                "p25": round(np.percentile(scores, 25), 2),
                "p50": round(np.percentile(scores, 50), 2),
                "p75": round(np.percentile(scores, 75), 2)
            }
        }

    def _organize_molecules_by_source(self, molecules_data):
        """æŒ‰æ¥æºç»„ç»‡åˆ†å­"""
        
        source_distribution = {}
        mol_id_counter = 1
        
        for source, mol_list in molecules_data.items():
            
            processed_mols = []
            
            for mol in mol_list:
                
                smiles = mol.get("smiles")
                if not smiles: continue
                
                # ä¸ºæ¯ä¸ªåˆ†å­åˆ›å»ºå”¯ä¸€çš„ID
                mol_id = f"MOL-{mol_id_counter}"
                mol_id_counter += 1
                
                # æ ‡å‡†åŒ–ç½®ä¿¡åº¦
                confidence = self._normalize_confidence(mol.get("score"))
                
                # æå–å…¶ä»–ä¿¡æ¯
                page = mol.get("page_number", -1)
                bbox = mol.get("bbox")
                mol_image_b64 = mol.get("image") # å‡è®¾å›¾ç‰‡æ˜¯base64ç¼–ç 
                
                # åˆ›å»ºåˆ†å­å¯¹è±¡
                mol_object = {
                    "id": mol_id,
                    "smiles": smiles,
                    "source": source,
                    "confidence": confidence,
                    "page": page,
                    "bbox": bbox,
                    "image_base64": mol_image_b64
                }
                
                processed_mols.append(mol_object)
                
            source_distribution[source] = {
                "count": len(processed_mols),
                "molecules": processed_mols
            }
            
        return source_distribution


    def _enhance_molecule_data(self, mol_data, mol_id):
        """ä½¿ç”¨RDKitè®¡ç®—åˆ†å­å±æ€§å¹¶å¢å¼ºæ•°æ®"""
        smiles = mol_data.get("smiles")
        mol = Chem.MolFromSmiles(smiles) if smiles else None
        
        properties = {
            "molecular_weight": None,
            "formula": None,
            "logP": None,
            "num_h_donors": None,
            "num_h_acceptors": None,
            "num_rotatable_bonds": None
        }
        
        if mol:
            properties["molecular_weight"] = round(Descriptors.MolWt(mol), 2)
            properties["formula"] = Chem.rdMolDescriptors.CalcMolFormula(mol)
            properties["logP"] = round(Crippen.MolLogP(mol), 2)
            properties["num_h_donors"] = Descriptors.NumHDonors(mol)
            properties["num_h_acceptors"] = Descriptors.NumHAcceptors(mol)
            properties["num_rotatable_bonds"] = Descriptors.NumRotatableBonds(mol)
            
        return {
            "id": mol_id,
            "smiles": smiles,
            "iupac_name": mol_data.get("iupac_name"), # å‡è®¾æ¨¡å‹å¯ä»¥æå–
            "properties": properties,
            "mentions": [{
                "source": mol_data.get("source", "unknown"),
                "confidence": self._normalize_confidence(mol_data.get("score")),
                "page": mol_data.get("page_number"),
                "bbox": mol_data.get("bbox")
            }]
        }

    def _normalize_confidence(self, score):
        """å°†ç½®ä¿¡åº¦åˆ†æ•°å½’ä¸€åŒ–åˆ°0-1èŒƒå›´"""
        if score is None:
            return None
        # å‡è®¾åˆ†æ•°å·²ç»æ˜¯0-1èŒƒå›´ï¼Œå¦‚æœä¸æ˜¯ï¼Œéœ€è¦è°ƒæ•´
        return round(float(score), 3)

    def _analyze_reactions(self, reactions_data):
        """åˆ†æå’Œæ ¼å¼åŒ–ååº”æ•°æ®"""
        reaction_list = self._format_reactions(reactions_data)
        return {
            "total_reactions": len(reaction_list),
            "reaction_list": reaction_list
        }

    def _format_reactions(self, reactions_data):
        """æ ¼å¼åŒ–ååº”æ•°æ®"""
        formatted_reactions = []
        reaction_id_counter = 1
        for rxn_data in reactions_data:
            rxn_id = f"RXN-{reaction_id_counter}"
            reaction_id_counter += 1
            
            # æå–å‚ä¸ç‰©
            reactants = [m["smiles"] for m in rxn_data.get("reactants", []) if m.get("smiles")]
            products = [m["smiles"] for m in rxn_data.get("products", []) if m.get("smiles")]
            
            # æå–æ¡ä»¶
            conditions_text = [c.get("text") for c in rxn_data.get("conditions", [])]
            
            formatted_reactions.append({
                "id": rxn_id,
                "reaction_smiles": f"{'.'.join(reactants)}>>{'.'.join(products)}",
                "reactants_smiles": reactants,
                "products_smiles": products,
                "conditions": conditions_text,
                "source": {
                    "page": rxn_data.get("page_number"),
                    "bbox": rxn_data.get("bbox")
                }
            })
        return formatted_reactions

    def _build_document_content(self, figures_data, tables_data):
        """æ„å»ºæ–‡æ¡£å†…å®¹éƒ¨åˆ†"""
        formatted_figures = self._format_figures_data(figures_data)
        formatted_tables = self._format_tables_data(tables_data)
        
        return {
            "figures": formatted_figures,
            "tables": formatted_tables
        }

    def _format_figures_data(self, figures_data):
        """æ ¼å¼åŒ–å›¾ç‰‡æ•°æ®"""
        formatted_figures = []
        figure_id_counter = 1
        
        for fig_data in figures_data:
            fig_id = f"FIG-{figure_id_counter}"
            figure_id_counter += 1
            
            # æå–æ ‡é¢˜å’Œè„šæ³¨
            caption = fig_data.get("title", {}).get("text", "")
            footnote = fig_data.get("footnote", {}).get("text", "")
            
            # æå–å›¾ç‰‡ä¿¡æ¯
            image_info = fig_data.get("figure", {})
            
            formatted_figures.append({
                "id": fig_id,
                "page": fig_data.get("page"),
                "bbox": image_info.get("bbox"),
                "caption": caption,
                "footnote": footnote,
                "image_base64": image_info.get("image") # å‡è®¾æ˜¯base64
            })
            
        return formatted_figures

    def _format_tables_data(self, tables_data):
        """æ ¼å¼åŒ–è¡¨æ ¼æ•°æ®"""
        formatted_tables = []
        table_id_counter = 1
        
        for tbl_data in tables_data:
            tbl_id = f"TBL-{table_id_counter}"
            table_id_counter += 1
            
            # æå–æ ‡é¢˜å’Œè„šæ³¨
            title = tbl_data.get("title", {}).get("text", "")
            footnote = tbl_data.get("footnote", {}).get("text", "")
            
            # æå–è¡¨æ ¼å†…å®¹
            table_content = tbl_data.get("table", {})
            table_structure = {}
            table_data = []

            if "content" in table_content and table_content["content"]:
                content = table_content["content"]
                table_structure = self._format_table_structure(content)
                table_data = self._format_table_data(content)

            formatted_tables.append({
                "id": tbl_id,
                "page": tbl_data.get("page"),
                "bbox": table_content.get("bbox"),
                "title": title,
                "footnote": footnote,
                "structure": table_structure,
                "data": table_data
            })
            
        return formatted_tables

    def _format_table_structure(self, content):
        """æ ¼å¼åŒ–è¡¨æ ¼ç»“æ„"""
        columns = content.get("columns", [])
        
        formatted_columns = []
        for i, col in enumerate(columns):
            formatted_columns.append({
                "index": i,
                "header": col.get("text", ""),
                "semantic_role": self._get_semantic_role(col.get("tag")),
                "data_type": self._classify_column_type(col.get("tag")) # åˆæ­¥åˆ†ç±»
            })
            
        return {
            "num_columns": len(formatted_columns),
            "num_rows": len(content.get("rows", [])),
            "columns": formatted_columns
        }
        
    def _classify_column_type(self, tag):
        """æ ¹æ®æ ‡ç­¾åˆæ­¥åˆ†ç±»åˆ—æ•°æ®ç±»å‹"""
        numeric_tags = ["measurement", "temperature", "time", "result", "ratio"]
        if tag in numeric_tags:
            return "numeric"
        
        categorical_tags = ["substance", "alkyl group", "solvent", "catalyst"]
        if tag in categorical_tags:
            return "categorical"
            
        return "text"
        
    def _get_semantic_role(self, tag):
        """è·å–åˆ—çš„è¯­ä¹‰è§’è‰²"""
        role_mapping = {
            "substance": "Reactant/Product",
            "reactant": "Reactant",
            "product": "Product",
            "catalyst": "Catalyst",
            "solvent": "Solvent",
            "temperature": "Condition-Temperature",
            "time": "Condition-Time",
            "yield": "Result-Yield",
            "ee": "Result-EnantiomericExcess",
            "ratio": "Stoichiometry"
        }
        return role_mapping.get(tag, "unknown")

    def _format_table_data(self, content):
        """æ ¼å¼åŒ–è¡¨æ ¼æ•°æ®"""
        rows = content.get("rows", [])
        columns = content.get("columns", [])
        
        formatted_rows = []
        for row_idx, row in enumerate(rows):
            formatted_row = {}
            for col_idx, cell in enumerate(row):
                header = columns[col_idx].get("text", f"col_{col_idx}")
                cell_text = cell.get("text", "")
                
                # åˆ†æå•å…ƒæ ¼å†…å®¹
                cell_type = self._classify_cell_type(cell_text)
                
                cell_data = {
                    "raw_text": cell_text,
                    "type": cell_type
                }
                
                if cell_type == "numeric":
                    cell_data["value"] = self._extract_numeric_value(cell_text)
                    cell_data["unit"] = self._extract_unit(cell_text)
                
                formatted_row[header] = cell_data
                
            formatted_rows.append(formatted_row)
            
        return formatted_rows

    def _classify_cell_type(self, text):
        """åˆ†ç±»å•å…ƒæ ¼æ•°æ®ç±»å‹"""
        if self._is_numeric(text):
            return "numeric"
        return "text"

    def _is_numeric(self, text):
        """åˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæ•°å€¼"""
        # åŒ¹é…æ•´æ•°ã€å°æ•°ã€ç§‘å­¦è®¡æ•°æ³•ã€èŒƒå›´
        # æ›´å®½æ¾çš„åŒ¹é…ï¼Œå…è®¸ç»“å°¾æœ‰å•ä½
        numeric_pattern = re.compile(r"^[-\u2212\s]*(\d{1,3}(,\d{3})*|\d+)(\.\d*)?([eE][+-]?\d+)?.*")
        range_pattern = re.compile(r".*(\d+\s*-\s*\d+).*") # å¦‚ "10-20"
        
        if numeric_pattern.match(text.strip()) or range_pattern.match(text.strip()):
            return True
        return False

    def _extract_numeric_value(self, text):
        """æå–æ•°å€¼"""
        # ç§»é™¤é€—å·åˆ†éš”ç¬¦
        text = text.replace(",", "")
        # åŒ¹é…æµ®ç‚¹æ•°æˆ–æ•´æ•°
        match = re.search(r"[-âˆ’\s]*\d+(\.\d*)?", text)
        return float(match.group(0).replace("âˆ’", "-")) if match else None
        
    def _extract_unit(self, text):
        """æå–å•ä½"""
        # ç§»é™¤æ•°å€¼éƒ¨åˆ†åï¼Œå‰©ä½™éƒ¨åˆ†ä½œä¸ºå•ä½
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–æ–¹æ³•ï¼Œå¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
        numeric_part = re.search(r"[-âˆ’\s]*\d+(\.\d*)?", text)
        if numeric_part:
            return text[numeric_part.end():].strip()
        return None

    def _build_relationships(self, corefs_data, molecules_data):
        """æ„å»ºå…³ç³»éƒ¨åˆ†"""
        formatted_corefs = self._format_coreferences(corefs_data, molecules_data)
        
        return {
            "coreferences": {
                "total_clusters": len(formatted_corefs),
                "clusters": formatted_corefs
            }
        }

    def _format_coreferences(self, corefs_data, molecules_data):
        """æ ¼å¼åŒ–å…±æŒ‡å…³ç³»"""
        
        # 1. åˆ›å»ºä¸€ä¸ªSMILESåˆ°åˆ†å­IDçš„æ˜ å°„
        smiles_to_id = {}
        for source, mol_list in molecules_data.items():
            for mol in mol_list:
                smiles = mol.get("smiles")
                if smiles and smiles not in smiles_to_id:
                    # å‡è®¾åˆ†å­IDåœ¨_enhance_molecule_dataä¸­å·²åˆ›å»º
                    # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ–¹å¼æ¥è·å–é‚£ä¸ªID
                    # ç®€åŒ–ï¼šæš‚æ—¶åªç”¨SMILESä½œä¸ºé”®
                    pass 

        # 2. å¤„ç†å…±æŒ‡é“¾
        clusters = []
        cluster_id_counter = 1
        
        if not isinstance(corefs_data, dict):
            return []

        for entity, coref_chains in corefs_data.items():
            
            if not isinstance(coref_chains, list): continue

            for chain in coref_chains:
                cluster_id = f"COREF-{cluster_id_counter}"
                cluster_id_counter += 1
                
                mentions = []
                
                # ä»£è¡¨æ€§æåŠ (é€šå¸¸æ˜¯ç¬¬ä¸€ä¸ª)
                representative_smiles = chain[0].get("smiles")
                
                for mention_data in chain:
                    # è·å–æåŠçš„åˆ†å­ID
                    # è¿™é‡Œéœ€è¦ä¸€ä¸ªæ›´å¯é çš„æœºåˆ¶æ¥å…³è”
                    # æš‚æ—¶ä½¿ç”¨SMILESæ¥æŸ¥æ‰¾
                    mention_smiles = mention_data.get("smiles")
                    
                    mentions.append({
                        "mention_id": f"MENTION-{len(mentions)+1}",
                        "molecule_smiles": mention_smiles,
                        "text_mention": mention_data.get("text"),
                        "source": {
                            "page": mention_data.get("page_number"),
                            "bbox": mention_data.get("bbox")
                        }
                    })
                
                clusters.append({
                    "cluster_id": cluster_id,
                    "representative_smiles": representative_smiles,
                    "mentions": mentions
                })
        
        return clusters

    def _calculate_quality_metrics(self, molecules_data, reactions_data, tables_data, corefs_data):
        """è®¡ç®—æå–è´¨é‡æŒ‡æ ‡"""
        # åˆ†å­ç½®ä¿¡åº¦
        mol_scores = [
            self._normalize_confidence(m.get("score")) 
            for m_list in molecules_data.values() 
            for m in m_list if m.get("score") is not None
        ]
        
        # ååº”ç½®ä¿¡åº¦ - å‡è®¾æœ‰
        rxn_scores = [
            r.get("confidence", 1.0) for r in reactions_data
        ]
        
        # è¡¨æ ¼æå–ç½®ä¿¡åº¦ - å‡è®¾æœ‰
        tbl_scores = [
            t.get("confidence", 1.0) for t in tables_data
        ]
        
        return {
            "molecule_extraction_confidence": self._analyze_confidence_distribution(mol_scores),
            "reaction_extraction_confidence": self._analyze_confidence_distribution(rxn_scores),
            "table_extraction_confidence": self._analyze_confidence_distribution(tbl_scores),
            "completeness_score": round(np.mean([1 if mol_scores else 0, 1 if reactions_data else 0, 1 if tables_data else 0]), 2)
        }

    def _calculate_statistics(self, results, processing_time):
        """è®¡ç®—æœ€ç»ˆç»Ÿè®¡æ•°æ®"""
        stats = {
            "total_processing_time_seconds": processing_time,
            "performance": {
                "pages_per_second": round(results["metadata"]["document_info"]["total_pages"] / processing_time, 2) if processing_time > 0 else 0,
                "cpu_usage_percent": psutil.cpu_percent(),
                "memory_usage_gb": round(psutil.virtual_memory().used / (1024**3), 2)
            },
            "counts": {
                "total_pages": results["metadata"]["document_info"]["total_pages"],
                "total_figures": results["document_structure"]["total_figures"],
                "total_tables": results["document_structure"]["total_tables"],
                "total_unique_molecules": results["chemical_entities"]["molecules"]["total_unique_molecules"],
                "total_reactions": results["chemical_entities"]["reactions"]["total_reactions"],
                "total_coref_clusters": results["relationships"]["coreferences"]["total_clusters"]
            }
        }
        return stats

    def _print_summary(self, results):
        """æ‰“å°æå–ç»“æœæ‘˜è¦"""
        print("\n" + "="*20 + " æå–æ‘˜è¦ " + "="*20)
        stats = results["statistics"]["counts"]
        print(f"ğŸ“„ å…±å¤„ç† {stats['total_pages']} é¡µ")
        print(f"ğŸ–¼ï¸ æ‰¾åˆ° {stats['total_figures']} ä¸ªå›¾ç‰‡, ğŸ“Š {stats['total_tables']} ä¸ªè¡¨æ ¼")
        print(f"ğŸ§ª æå–äº† {stats['total_unique_molecules']} ä¸ªç‹¬ç«‹åˆ†å­")
        print(f"âš—ï¸ è¯†åˆ«äº† {stats['total_reactions']} ä¸ªåŒ–å­¦ååº”")
        print(f"ğŸ”— å‘ç°äº† {stats['total_coref_clusters']} ä¸ªå…±æŒ‡é“¾")
        print("="*55)
        
    def save_results(self, results, output_path):
        """
        å°†æå–ç»“æœä¿å­˜ä¸ºJSONæ–‡ä»¶
        
        Args:
            results (dict): æå–ç»“æœ
            output_path (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„ (JSON)
        """
        output_dir = os.path.dirname(output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
            
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=4)
        
        if self.verbose:
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {output_path}")

def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºå‘½ä»¤è¡Œæ“ä½œ"""
    parser = argparse.ArgumentParser(description="OpenChemIE v2.0 - ä»PDFä¸­æå–åŒ–å­¦ä¿¡æ¯")
    parser.add_argument("pdf_path", type=str, help="è¾“å…¥çš„PDFæ–‡ä»¶è·¯å¾„")
    parser.add_argument("-o", "--output", type=str, default=None, help="è¾“å‡ºçš„JSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--no-images", action="store_true", help="ä¸è¾“å‡ºæå–çš„å›¾ç‰‡")
    parser.add_argument("--no-bbox", action="store_true", help="ä¸è¾“å‡ºè¾¹ç•Œæ¡†ä¿¡æ¯")
    parser.add_argument("--no-corefs", action="store_true", help="ä¸æå–å…±æŒ‡å…³ç³»")
    parser.add_argument("--device", type=str, default=None, help="è®¡ç®—è®¾å¤‡ (ä¾‹å¦‚ 'cuda:0' æˆ– 'cpu')")
    parser.add_argument("-q", "--quiet", action="store_true", help="å®‰é™æ¨¡å¼ï¼Œä¸æ‰“å°è¯¦ç»†ä¿¡æ¯")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æå–å™¨
    extractor = OpenChemIEExtractorV2(device=args.device, verbose=not args.quiet)
    
    # æå–ä¿¡æ¯
    results = extractor.extract_from_pdf(
        args.pdf_path,
        output_images=not args.no_images,
        output_bbox=not args.no_bbox,
        extract_corefs=not args.no_corefs
    )
    
    # ä¿å­˜ç»“æœ
    if args.output:
        output_path = args.output
    else:
        # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        base_name = Path(args.pdf_path).stem
        output_path = f"{base_name}_openchemie_results.json"
        
    extractor.save_results(results, output_path)

if __name__ == '__main__':
    main()
