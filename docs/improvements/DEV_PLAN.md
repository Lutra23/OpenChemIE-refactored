# OpenChemIE æ™ºèƒ½åŒ–å‡çº§ â€“ ç‰ˆæœ¬åŒ–ä»»åŠ¡è®¡åˆ’ (DEV_PLAN)

> æœ¬æ–‡ä»¶æŒ‰ç…§ **Version 1.0 / 2.0 / 3.0** ä¸‰ä¸ªé˜¶æ®µç»„ç»‡ï¼Œé‡‡ç”¨ `TASKxxx` ç¼–å·æè¿°æœ€å°å¯è¡Œä»»åŠ¡ï¼Œä¾¿äº Taskmaster-AI æˆ–äººå·¥å¼€å‘è€…é€é¡¹æ‰§è¡Œã€è¿½è¸ªä¸éªŒæ”¶ã€‚

---

## ğŸ“š ç‰ˆæœ¬ç´¢å¼•
- [Version 1.0 â€“ Minimal Viable Product](#version-10--minimal-viable-product)
- [Version 2.0 â€“ Local LLM Integration](#version-20--local-llm-integration)
- [Version 3.0 â€“ Multimodal Enhancement & Optimization](#version-30--multimodal-enhancement--optimization)

---

## Version 1.0 â€“ Minimal Viable Product

### TASK001 â€“ åˆå§‹åŒ–å¼€å‘ç¯å¢ƒä¸ä¾èµ–é”å®š
- **Version**: 1.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. åœ¨ `requirements.txt` ä½¿ç”¨ `~=` é”å®šæ ¸å¿ƒä¾èµ–ç‰ˆæœ¬ã€‚
2. ç”Ÿæˆ `requirements-lock.txt` (`pip-compile`).
3. åˆ›å»º **DevContainer** (Ubuntu 22.04 + Python 3.10)ã€‚
4. é…ç½® `pre-commit` (black, ruff, isort, mypy)ã€‚

#### ğŸ¤– AI Assistant Prompt (å®Œæ•´ç¤ºä¾‹)
```prompt
You are an advanced AI pair-programmer working on OpenChemIE.
Goal: å®Œæˆ TASK001 çš„å…¨éƒ¨å­ä»»åŠ¡å¹¶æ¨é€åˆ° Git ä»“åº“ã€‚
Constraints:
1. Preserve existing project structure.
2. Use ~= for version pinning; freeze to requirements-lock.txt via pip-compile.
3. Ensure pre-commit hooks run without error on initial commit.
4. All changes must pass CI (pytest, lint) before merge.
Output: Git diff with added files & updated requirements.
Failure policy: å¦‚æœä»»ä½•æ­¥éª¤å¤±è´¥ï¼Œè‡ªåŠ¨å›æ»šå¹¶è¾“å‡ºæ•…éšœåŸå› ã€‚
```

#### éªŒæ”¶æ ‡å‡†
- `pip install -r requirements-lock.txt` å¯å®Œæ•´å¤ç°ç¯å¢ƒã€‚
- `pre-commit run --all-files` æ— é”™è¯¯ã€‚
- DevContainer å¯åŠ¨å `python --version` == 3.10.xã€‚

#### æ³¨æ„äº‹é¡¹
- é”å®šæ–‡ä»¶é¡»åŠ å…¥ç‰ˆæœ¬æ§åˆ¶ï¼ˆé¿å… `.gitignore` æ’é™¤ï¼‰ã€‚
- Windows ç”¨æˆ·éœ€å•ç‹¬æµ‹è¯• PowerShell å®‰è£…è„šæœ¬ã€‚

---

### TASK002 â€“ ä»£ç ç»“æ„é‡ç»„ï¼šæ¨¡å—åŒ– Skeleton
- **Version**: 1.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. åˆ›å»º `openchemie/core/`, `openchemie/models/`, `openchemie/pipelines/`, `openchemie/llm/` ç›®å½•ã€‚
2. å°†ç°æœ‰ `interface.py` å†…å®¹æ‹†åˆ†ä¸º `core/base.py` ä¸ç¤ºä¾‹ç®¡çº¿æ–‡ä»¶ã€‚
3. æ›´æ–° `__init__.py` å¯¼å‡ºå…¬å…±æ¥å£ã€‚
4. è°ƒæ•´å•å…ƒæµ‹è¯•è·¯å¾„ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
Objective: Refactor interface.py into modular skeleton.
Steps:
- Move abstracts to core/base.py
- Keep API routers unchanged.
- Ensure existing unit tests still pass.
Return: Patch ready to commit.
```

#### éªŒæ”¶æ ‡å‡†
- æ‰€æœ‰ `pytest` æµ‹è¯•é€šè¿‡ã€‚
- `openchemie` ç›®å½•ç¬¦åˆæ–°çš„å±‚çº§ç»“æ„ã€‚

#### æ³¨æ„äº‹é¡¹
- ä¿ç•™å†å² import å…¼å®¹æ€§ï¼ˆæ·»åŠ ä¸´æ—¶åˆ«åï¼‰ã€‚

---

### TASK003 â€“ DeviceManager æŠ½è±¡
- **Version**: 1.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. å®ç° `DeviceManager` æ£€æµ‹ CUDA/MPS/CPUã€‚
2. æä¾› `allocate_model()` API æ”¯æŒæ˜¾å­˜æ£€æŸ¥ã€‚
3. ç¼–å†™å•å…ƒæµ‹è¯•æ¨¡æ‹Ÿä¸åŒç¡¬ä»¶ç¯å¢ƒã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
Implement DeviceManager with auto GPU/CPU switch.
Include memory threshold config and unit tests (pytest, monkeypatch torch.cuda.is_available).
```

#### éªŒæ”¶æ ‡å‡†
- `pytest tests/device_manager.py` 100% é€šè¿‡ã€‚

#### æ³¨æ„äº‹é¡¹
- å…¼å®¹æ—  CUDA ç¯å¢ƒã€‚

---

### TASK004 â€“ ProcessorRegistry æ’ä»¶æœºåˆ¶
- **Version**: 1.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. æ–°å»º `openchemie/core/registry.py`ï¼Œå®ç° `ProcessorRegistry`ï¼ˆ`register()`, `get()`, `list()`ï¼‰ã€‚
2. æ”¯æŒ `@processor_registry.register("name")` è£…é¥°å™¨ç®€åŒ–æ³¨å†Œã€‚
3. åœ¨ `openchemie/pipelines/__init__.py` ä¸­ç¤ºä¾‹æ³¨å†Œ `PdfPipelineProcessor`ã€‚
4. ç¼–å†™å•å…ƒæµ‹è¯• `tests/test_registry.py`ï¼Œè¦†ç›–ç‡ â‰¥ 90%ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
Objective: Implement dynamic plugin registry (TASK004).
Steps:
1. Create ProcessorRegistry with thread-safe register/get/list.
2. Provide decorator for syntactic sugar.
3. Add example processor registration in pipelines package.
4. Write pytest unit tests with >90% coverage.
Constraints: Keep backward compatibility, no external deps.
Rollback: On import/test failure, revert and output traceback.
```

#### éªŒæ”¶æ ‡å‡†
- åŠ¨æ€æ³¨å†Œã€æ£€ç´¢ã€åˆ—å‡ºåŠŸèƒ½é€šè¿‡æµ‹è¯•ã€‚  
- è£…é¥°å™¨æ³¨å†Œè¯­æ³•å¯åœ¨ç¤ºä¾‹ä¸­æ­£å¸¸ä½¿ç”¨ã€‚  
- `pytest -q` å…¨éƒ¨é€šè¿‡ï¼Œè¦†ç›–ç‡æŠ¥å‘Š â‰¥ 90%ã€‚

#### æ³¨æ„äº‹é¡¹
- é˜²æ­¢å¾ªç¯ä¾èµ–å¯¼è‡´çš„ ImportErrorã€‚
- Registry æ¨èå•ä¾‹å®ç°ï¼Œé¿å…å¤šé‡å®ä¾‹åŒ–ã€‚

---

### TASK005 â€“ å•å…ƒæµ‹è¯•åŸºçº¿ & CI ç®¡é“
- **Version**: 1.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. åˆå§‹åŒ– `tests/` ç›®å½•ä¸ `conftest.py`ã€‚
2. æ·»åŠ ç¤ºä¾‹æµ‹è¯• `tests/test_smoke.py` éªŒè¯ API æ ¹è·¯ç”±è¿”å› 200ã€‚
3. é…ç½® `pytest.ini`ï¼ˆå« `addopts = -q --cov=openchemie --cov-report=term-missing`ï¼‰ã€‚
4. åœ¨ `.github/workflows/ci.yml` è®¾ç½® GitHub Actionsï¼š`lint -> test -> build-docker` ä¸‰é˜¶æ®µã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
Goal: Establish testing baseline & CI (TASK005).
Deliverables:
- pytest config & smoke test.
- GitHub Actions workflow (Python 3.10, cache deps).
- Coverage threshold 70% (fail below).
Ensure: workflow green on first run.
```

#### éªŒæ”¶æ ‡å‡†
- æœ¬åœ° `pytest` è¿è¡Œé€šè¿‡ï¼Œåˆå§‹è¦†ç›–ç‡ â‰¥ 70%ã€‚
- GitHub Actions æ‰§è¡ŒæˆåŠŸï¼Œæ— å¤±è´¥æ­¥éª¤ã€‚

#### æ³¨æ„äº‹é¡¹
- ä½¿ç”¨ `actions/setup-python` ç¼“å­˜ä¾èµ–ç¼©çŸ­æ—¶é—´ã€‚  
- Docker build æ­¥éª¤å¯ä½¿ç”¨ `--target test` ç²¾ç®€é•œåƒä½“ç§¯ã€‚

---

### TASK006 â€“ Docker & DevContainer é…ç½®
- **Version**: 1.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. ç²¾ç®€ `infra/Dockerfile.api`ï¼Œé‡‡ç”¨å¤šé˜¶æ®µæ„å»ºï¼Œæœ€ç»ˆé•œåƒ < 1.5 GBã€‚
2. æ›´æ–° `infra/docker-compose.yml`ï¼Œæ”¯æŒ GPU ä¸ CPU ä¸¤ç§ profile (`--profile gpu`).
3. åˆ›å»º `.devcontainer/devcontainer.json`ï¼Œæ˜ å°„ `Dockerfile.dev`ã€‚
4. ç¼–å†™æ–‡æ¡£ `docs/DEPLOY_DOCKER.md`ï¼Œè¯´æ˜æœ¬åœ°ä¸ç”Ÿäº§éƒ¨ç½²æ­¥éª¤ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
TASK006: Optimize Docker & DevContainer.
Requirements:
- Multi-stage build; final image <1.5GB.
- docker-compose gpu profile uses nvidia runtime.
- DevContainer launches api + redis services.
- Provide deployment docs.
```

#### éªŒæ”¶æ ‡å‡†
- `docker compose build` å®Œæˆä¸”é•œåƒä½“ç§¯æ»¡è¶³è¦æ±‚ã€‚
- åœ¨ VS Code Remote Containers ä¸­å¯æˆåŠŸå¯åŠ¨å¹¶è®¿é—® API `/docs`ã€‚

#### æ³¨æ„äº‹é¡¹
- ç¡®ä¿ `.dockerignore` æ’é™¤ `models/` å·¨å¤§æ–‡ä»¶å¤¹ã€‚  
- GPU profile ä»…åœ¨æ£€æµ‹åˆ° `nvidia-smi` æ—¶å¯ç”¨ã€‚

---

## Version 2.0 â€“ Local LLM Integration

### TASK201 â€“ Ollama + Qwen2.5-7B éƒ¨ç½²è„šæœ¬
- **Version**: 2.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. ç¼–å†™ `scripts/install_ollama.sh`ï¼Œè‡ªåŠ¨å®‰è£… Ollama (Linux/macOS)ã€‚
2. ç¼–å†™ `scripts/download_models.sh` ä¸‹è½½ `qwen2.5:7b` å¹¶æ ¡éªŒ SHA256ã€‚
3. åœ¨ `infra/docker-compose.yml` æ–°å¢ `ollama` æœåŠ¡ã€‚
4. æ›´æ–° README éƒ¨ç½²æŒ‡å—ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
Objective: Provide reproducible Ollama + Qwen2.5-7B deployment (TASK201).
Steps: write install & model scripts, compose service, docs.
Ensure scripts idempotent, exit on error.
```

#### éªŒæ”¶æ ‡å‡†
- è¿è¡Œè„šæœ¬å `ollama list` åŒ…å« `qwen2.5:7b`ã€‚  
- `docker compose up -d ollama` å¯åŠ¨æˆåŠŸå¹¶å¯é€šè¿‡ 11434 ç«¯å£è®¿é—®ã€‚

#### æ³¨æ„äº‹é¡¹
- å›½å†…ç”¨æˆ·éœ€æä¾›é•œåƒåŠ é€Ÿæºã€‚  
- è„šæœ¬éœ€ä½¿ç”¨ `set -euo pipefail`ã€‚

---

### TASK202 â€“ LocalLLMClient å°è£…
- **Version**: 2.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. åˆ›å»º `openchemie/llm/client.py`ï¼Œå°è£… async Ollama HTTP è°ƒç”¨ã€‚
2. å®ç° `query()` ä¸ `batch_query()`ï¼›æ”¯æŒæ¸©åº¦ã€top_p å‚æ•°ã€‚
3. æ·»åŠ é‡è¯•ä¸è¶…æ—¶é€»è¾‘ (`tenacity`).
4. ç¼–å†™å•å…ƒæµ‹è¯•ä½¿ç”¨ `httpx.MockTransport`ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
TASK202: Implement LocalLLMClient.
Interfaces: query(), batch_query().
Handle retries (3) & 30-s timeout.
Mock Ollama API in tests.
```

#### éªŒæ”¶æ ‡å‡†
- `pytest tests/test_llm_client.py` å…¨éƒ¨é€šè¿‡ã€‚
- èƒ½åœ¨ 2s å†…å®Œæˆæ‰¹é‡ 5 æ¡ mock è¯·æ±‚ã€‚

#### æ³¨æ„äº‹é¡¹
- é¿å…åœ¨å®¢æˆ·ç«¯ä¸­ç¡¬ç¼–ç æ¨¡å‹åï¼›é€šè¿‡å‚æ•°æ³¨å…¥ã€‚

---

### TASK203 â€“ æ™ºèƒ½ R åŸºå›¢è¯†åˆ«å™¨
- **Version**: 2.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. æ–°å»º `openchemie/llm/rgroup_extractor.py`ã€‚
2. è®¾è®¡ prompt æ¨¡æ¿æ”¯æŒæ¡ä»¶å¼å®šä¹‰ã€‚
3. è°ƒç”¨ LocalLLMClient å®Œæˆè§£æå¹¶è¿”å›ç»“æ„åŒ– JSONã€‚
4. ç¼–å†™ 20 æ¡æ ·ä¾‹çš„é›†æˆæµ‹è¯•ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
Design & implement intelligent R-group extractor using Qwen2.5 (TASK203).
Return JSON: name, definition, conditions, confidence.
```

#### éªŒæ”¶æ ‡å‡†
- 20 æ¡æ ·ä¾‹å¹³å‡ F1 â‰¥ 0.88ã€‚

#### æ³¨æ„äº‹é¡¹
- ä¸ºæ¯æ¡è¿”å›å¢åŠ  `confidence` å­—æ®µï¼Œä¾¿äºåç»­è´¨é‡è¯„ä¼°ã€‚

---

### TASK204 â€“ ååº”æ¡ä»¶è¯­ä¹‰è§£æå™¨
- **Version**: 2.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. å»ºç«‹ prompt æ¨¡æ¿è§£æå‚¬åŒ–å‰‚ã€æ°”æ°›ç­‰ä¿¡æ¯ã€‚
2. æ”¯æŒè¿”å›æœºåˆ¶æ¨æ–­å­—æ®µ `mechanism`ã€‚
3. æ·»åŠ é™çº§é€»è¾‘ï¼šLLM å¤±è´¥å›é€€è§„åˆ™è§£æã€‚
4. æµ‹è¯•è¦†ç›– 30 æ¡æ ‡å‡†ååº”æè¿°ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
TASK204: Build SemanticReactionConditionParser.
Parse catalyst, atmosphere, parameters, mechanism.
Provide graceful fallback.
```

#### éªŒæ”¶æ ‡å‡†
- F1 â‰¥ 0.80 åœ¨æµ‹è¯•é›†ã€‚

#### æ³¨æ„äº‹é¡¹
- æ­£åˆ™å›é€€éœ€ä¸æ—§ç‰ˆé€»è¾‘å…¼å®¹ã€‚

---

### TASK205 â€“ å…±æŒ‡å…³ç³»å¢å¼ºå™¨
- **Version**: 2.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. å®ç° `ContextualCoreferenceResolver` è°ƒç”¨ LLMã€‚
2. æ”¯æŒ `resolve_advanced_coreferences()` APIã€‚
3. é›†æˆè‡³ç°æœ‰æå–æµæ°´çº¿ã€‚
4. ç¼–å†™é•¿æ–‡æœ¬æ€§èƒ½åŸºå‡†ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
TASK205: Implement advanced coreference resolver using LLM.
Focus on "the product" ambigious terms.
```

#### éªŒæ”¶æ ‡å‡†
- åœ¨åŸºå‡†æ–‡æ¡£é›†ä¸Šå…±æŒ‡å‡†ç¡®ç‡æå‡ â‰¥15%ã€‚

#### æ³¨æ„äº‹é¡¹
- æ³¨æ„å†…å­˜å ç”¨ï¼Œé•¿æ–‡åˆ‡ç‰‡å¤„ç†ã€‚

---

### TASK206 â€“ é™çº§/å›é€€æœºåˆ¶å®ç°
- **Version**: 2.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. åœ¨ `openchemie/settings.py` å¢åŠ  `LLM_FALLBACK_ENABLED`ã€‚
2. åœ¨å„ LLM æ¨¡å—åŒ…è£¹ `try/except`ï¼Œå›é€€æ—§ç®—æ³•ã€‚
3. è®°å½•é™çº§äº‹ä»¶æ—¥å¿—åˆ° `logs/llm_fallback.log`ã€‚
4. å•å…ƒæµ‹è¯•æ¨¡æ‹Ÿ LLM è¶…æ—¶è§¦å‘å›é€€ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
TASK206: Implement robust fallback when LLM fails.
Log fallback events and continue pipeline.
```

#### éªŒæ”¶æ ‡å‡†
- æ¨¡æ‹Ÿå¤±è´¥æ—¶ä»å¯è¿”å›æ—§ç®—æ³•ç»“æœã€‚
- æ—¥å¿—è®°å½•åŒ…å« timestamp / module / reasonã€‚

#### æ³¨æ„äº‹é¡¹
- é¿å…åå¹¶åŸå§‹å¼‚å¸¸ï¼Œä¾¿äºè°ƒè¯•ã€‚

---

### TASK207 â€“ LLM æ€§èƒ½åŸºå‡†ä¸ç›‘æ§
- **Version**: 2.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. ä½¿ç”¨ `locust` æˆ– `pytest-benchmark` è¯„ä¼° QPS & latencyã€‚
2. æ•´åˆ `prometheus_client` è¾“å‡º `/metrics`ã€‚
3. åœ¨ Grafana å¯¼å…¥é»˜è®¤ä»ªè¡¨æ¿ã€‚
4. å†™æ€§èƒ½æŠ¥å‘Š `docs/perf/llm_baseline.md`ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
TASK207: Benchmark & monitor LLM service.
Provide Prometheus metrics and Grafana dashboard JSON.
```

#### éªŒæ”¶æ ‡å‡†
- QPS â‰¥ 5 (batch size 1) on RTX 4060ã€‚
- `/metrics` æš´éœ²ä¸»è¦æŒ‡æ ‡ã€‚

#### æ³¨æ„äº‹é¡¹
- åŸºå‡†éœ€æ’é™¤é¦–æ¬¡åŠ è½½çš„å†·å¯åŠ¨æ—¶é—´ã€‚

---

## Version 3.0 â€“ Multimodal Enhancement & Optimization

### TASK301 â€“ Gemini å¤šæ¨¡æ€æ ¡éªŒé›†æˆ
- **Version**: 3.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. åœ¨ `openchemie/llm/multimodal_validator.py` é›†æˆ Google GenerativeAI SDKã€‚
2. å°è£… `validate_extraction(pdf, json)` æ–¹æ³•ã€‚
3. å¤„ç† `403/429` é”™è¯¯å¹¶é™çº§æœ¬åœ°è¯„ä¼°ã€‚
4. å•å…ƒæµ‹è¯•ä½¿ç”¨ mock SDKã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
TASK301: Integrate Gemini 2.5 Flash for multimodal validation.
Ensure cost control via feature toggle.
```

#### éªŒæ”¶æ ‡å‡†
- æˆåŠŸè¿”å›ç½®ä¿¡åº¦è¯„åˆ† JSONã€‚
- è°ƒç”¨æ¬¡æ•°è®¡æ•°å™¨å¯åœ¨ `/metrics` æŸ¥çœ‹ã€‚

#### æ³¨æ„äº‹é¡¹
- é»˜è®¤å…³é—­äº‘ç«¯éªŒè¯ï¼Œéœ€æ˜¾å¼ `--enhanced` å‚æ•°ã€‚

---

### TASK302 â€“ MultimodalValidator æœåŠ¡
- **Version**: 3.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. æ–°å»º FastAPI è·¯ç”± `/validate/multimodal/`ã€‚
2. æ”¯æŒæ–‡ä»¶ä¸Šä¼  + ç»“æœ JSON è¾“å…¥ã€‚
3. è¿”å›æ ¡æ­£å»ºè®®åŠå›¾è¡¨å·®å¼‚ã€‚
4. å‰ç«¯æä¾› REST è°ƒç”¨ç¤ºä¾‹ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
TASK302: Build REST service wrapping MultimodalValidator.
```

#### éªŒæ”¶æ ‡å‡†
- Swagger æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆå¹¶å¯è°ƒè¯•ã€‚

#### æ³¨æ„äº‹é¡¹
- ä¸Šä¼ æ–‡ä»¶å¤§å°é™åˆ¶ 10 MBã€‚

---

### TASK303 â€“ å‰ç«¯ç»“æœå¯¹æ¯”è§†å›¾
- **Version**: 3.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. åœ¨ Vue3 æ–°å»ºç»„ä»¶ `ResultComparer.vue`ã€‚
2. ä½¿ç”¨ ECharts æ¸²æŸ“å·®å¼‚é›·è¾¾å›¾ã€‚
3. æ”¯æŒ JSON diff é«˜äº®ã€‚
4. ç¼–å†™å•å…ƒæµ‹è¯•ä½¿ç”¨ Vitestã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
TASK303: Implement interactive result comparison view using Vue3 + ECharts.
```

#### éªŒæ”¶æ ‡å‡†
- èƒ½åŠ è½½ API ç»“æœå¹¶æ˜¾ç¤ºå·®å¼‚å›¾è¡¨ã€‚

#### æ³¨æ„äº‹é¡¹
- ä¿è¯ç§»åŠ¨ç«¯å“åº”å¼å¸ƒå±€ã€‚

---

### TASK304 â€“ è´¨é‡è¯„ä¼°ä»ªè¡¨æ¿
- **Version**: 3.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. åœ¨ Grafana åˆ›å»º Extraction Quality Dashboardã€‚
2. æŒ‡æ ‡ï¼šmolecular_confidence, reaction_confidence, overall_confidenceã€‚
3. å¯¼å‡º JSON é…ç½®åˆ° `infra/grafana_dashboards/`ã€‚
4. æ–‡æ¡£ `docs/monitoring/quality_dashboard.md`ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
TASK304: Build Grafana dashboard for extraction quality metrics.
```

#### éªŒæ”¶æ ‡å‡†
- Dashboard JSON è¢« Grafana æˆåŠŸå¯¼å…¥ã€‚

#### æ³¨æ„äº‹é¡¹
- ä½¿ç”¨å˜é‡æ”¯æŒå¤šç¯å¢ƒåˆ‡æ¢ã€‚

---

### TASK305 â€“ å†…å­˜å¤ç”¨ä¸æ‰¹å¤„ç†è°ƒåº¦ä¼˜åŒ–
- **Version**: 3.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. å®ç° `MemoryManager` å¸è½½æœ€å°‘ä½¿ç”¨æ¨¡å‹ã€‚
2. æ ¹æ® PDF é¡µæ•°åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°ã€‚
3. åœ¨æ‰¹å¤„ç†æœåŠ¡åŠ å…¥ `semaphore` æ§åˆ¶ã€‚
4. åŸºå‡†æµ‹è¯•æ˜¾å­˜å ç”¨ä¸ååã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
TASK305: Optimize memory reuse & batch scheduler.
```

#### éªŒæ”¶æ ‡å‡†
- GPU/CPU å†…å­˜å ç”¨ä¸‹é™ â‰¥ 20%ã€‚
- Batch TPS æå‡ â‰¥ 30%ã€‚

#### æ³¨æ„äº‹é¡¹
- é¿å…é¢‘ç¹åŠ è½½/å¸è½½å¯¼è‡´æŠ–åŠ¨ã€‚

---

### TASK306 â€“ ç”Ÿäº§éƒ¨ç½²æµæ°´çº¿ & ç›‘æ§
- **Version**: 3.0  
- **Status**: è®¡åˆ’ä¸­

#### å­ä»»åŠ¡
1. åœ¨ GitHub Actions æ·»åŠ  `release.yml`ï¼Œæ¨é€ tag æ—¶æ„å»ºå¹¶å‘å¸ƒ Docker é•œåƒã€‚
2. ä½¿ç”¨ `infra/k8s/` Helm Chart éƒ¨ç½²åˆ°ç”Ÿäº§é›†ç¾¤ã€‚
3. é…ç½® Prometheus Operator æŠ“å– `/metrics`ã€‚
4. ç¼–å†™ `runbook.md` æè¿°æ•…éšœæ’æŸ¥æµç¨‹ã€‚

#### ğŸ¤– AI Assistant Prompt
```prompt
TASK306: Build production-grade deployment pipeline & monitoring.
```

#### éªŒæ”¶æ ‡å‡†
- Tag push è‡ªåŠ¨å‘å¸ƒå¹¶å¯åœ¨é›†ç¾¤è®¿é—®ã€‚
- Prometheus & Grafana å±•æ¿æ˜¾ç¤ºå®æ—¶æŒ‡æ ‡ã€‚

#### æ³¨æ„äº‹é¡¹
- Helm Chart éœ€æ”¯æŒ CPU/GPU é€‰é¡¹ã€‚

---

> **æ›´æ–°è®°å½•**  
> 2025-03-01 â€“ é‡æ„ä¸ºç‰ˆæœ¬åŒ– TASK æ ¼å¼ (by AI Assistant) 