#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenChemIE WebæœåŠ¡å¯åŠ¨è„šæœ¬ - æ€§èƒ½ä¼˜åŒ–ç‰ˆ
"""

import os
import sys
import torch
import psutil
from pathlib import Path

def check_system_requirements():
    """æ£€æŸ¥ç³»ç»Ÿè¦æ±‚å’Œæ€§èƒ½é…ç½®"""
    print("ğŸ” ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥...")
    
    # Pythonç‰ˆæœ¬æ£€æŸ¥
    python_version = sys.version_info
    if python_version < (3, 8):
        print(f"âš ï¸ Pythonç‰ˆæœ¬ {python_version.major}.{python_version.minor} å¯èƒ½ä¸å…¼å®¹ï¼Œå»ºè®®ä½¿ç”¨Python 3.8+")
    else:
        print(f"âœ… Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # CUDAæ£€æŸ¥
    cuda_available = torch.cuda.is_available()
    if cuda_available:
        gpu_count = torch.cuda.device_count()
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"âœ… CUDAå¯ç”¨: {gpu_count}å—GPU")
        print(f"   ğŸ“± ä¸»GPU: {gpu_name} ({gpu_memory:.1f}GB)")
    else:
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUï¼ˆè¾ƒæ…¢ï¼‰")
        print("   ğŸ’¡ å»ºè®®ï¼šå®‰è£…CUDAç‰ˆæœ¬çš„PyTorchä»¥è·å¾—æ›´å¥½æ€§èƒ½")
    
    # å†…å­˜æ£€æŸ¥
    memory = psutil.virtual_memory()
    memory_gb = memory.total / 1024**3
    print(f"ğŸ’¾ ç³»ç»Ÿå†…å­˜: {memory_gb:.1f}GB (å¯ç”¨: {memory.available/1024**3:.1f}GB)")
    
    if memory_gb < 8:
        print("âš ï¸ å†…å­˜è¾ƒå°‘ï¼Œå»ºè®®å…³é—­å›¾ç‰‡è¾“å‡ºå’Œå…±æŒ‡å…³ç³»æå–")
    elif memory_gb < 16:
        print("ğŸ’¡ å†…å­˜é€‚ä¸­ï¼Œå»ºè®®é€‚åº¦ä½¿ç”¨é«˜çº§åŠŸèƒ½")
    else:
        print("âœ… å†…å­˜å……è¶³ï¼Œæ”¯æŒæ‰€æœ‰åŠŸèƒ½")
    
    # CPUæ£€æŸ¥
    cpu_count = psutil.cpu_count()
    cpu_freq = psutil.cpu_freq()
    print(f"ğŸš€ CPU: {cpu_count}æ ¸å¿ƒ")
    if cpu_freq:
        print(f"   âš¡ é¢‘ç‡: {cpu_freq.current:.0f}MHz")
    
    return cuda_available, memory_gb

def optimize_torch_settings():
    """ä¼˜åŒ–PyTorchè®¾ç½®"""
    print("\nâš™ï¸ ä¼˜åŒ–PyTorchè®¾ç½®...")
    
    # è®¾ç½®çº¿ç¨‹æ•°
    cpu_count = psutil.cpu_count()
    torch.set_num_threads(min(cpu_count, 8))  # é™åˆ¶çº¿ç¨‹æ•°é¿å…è¿‡è½½
    print(f"ğŸ”§ PyTorchçº¿ç¨‹æ•°: {torch.get_num_threads()}")
    
    # å†…å­˜ä¼˜åŒ–
    if torch.cuda.is_available():
        torch.backends.cudnn.benchmark = True  # ä¼˜åŒ–å·ç§¯æ€§èƒ½
        torch.cuda.empty_cache()  # æ¸…ç†GPUç¼“å­˜
        print("ğŸ¯ å¯ç”¨CUDNNä¼˜åŒ–")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['OMP_NUM_THREADS'] = str(min(cpu_count, 8))
    os.environ['MKL_NUM_THREADS'] = str(min(cpu_count, 8))
    
def show_performance_tips(cuda_available, memory_gb):
    """æ˜¾ç¤ºæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
    print("\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
    
    if not cuda_available:
        print("   ğŸ“± å®‰è£…CUDAç‰ˆæœ¬PyTorchå¯å¤§å¹…æå‡é€Ÿåº¦")
        print("   ğŸ”— https://pytorch.org/get-started/locally/")
    
    if memory_gb < 16:
        print("   ğŸ’¾ å†…å­˜ä¸è¶³æ—¶å»ºè®®:")
        print("      â€¢ å…³é—­'ä¿å­˜æå–å›¾ç‰‡'é€‰é¡¹")
        print("      â€¢ å…³é—­'æå–åˆ†å­å…±æŒ‡å…³ç³»'é€‰é¡¹")
        print("      â€¢ å•ä¸ªæ–‡ä»¶å¤„ç†ï¼Œé¿å…æ‰¹é‡ä¸Šä¼ ")
    
    print("   âš¡ æ€§èƒ½è®¾ç½®å»ºè®®:")
    print("      â€¢ è®¾å¤‡é€‰æ‹©: " + ("GPU (æ¨è)" if cuda_available else "CPU"))
    print("      â€¢ å¹¶å‘ä»»åŠ¡: å»ºè®®ä¸è¶…è¿‡2ä¸ª")
    print("      â€¢ å®šæœŸæ¸…ç†ç¼“å­˜å’Œæ—§ä»»åŠ¡")
    
def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨ OpenChemIE Webç•Œé¢ (æ€§èƒ½ä¼˜åŒ–ç‰ˆ)...")
    print("=" * 50)
    
    # ç³»ç»Ÿæ£€æŸ¥
    cuda_available, memory_gb = check_system_requirements()
    
    # ä¼˜åŒ–è®¾ç½®
    optimize_torch_settings()
    
    # æ€§èƒ½å»ºè®®
    show_performance_tips(cuda_available, memory_gb)
    
    print("\n" + "=" * 50)
    print("ğŸŒ WebæœåŠ¡ä¿¡æ¯:")
    print("ğŸ“± è®¿é—®åœ°å€: http://localhost:5001")
    print("ğŸ“Š æ€§èƒ½ç›‘æ§: http://localhost:5001 -> æ€§èƒ½ç›‘æ§")
    print("ğŸ“ å†å²è®°å½•: http://localhost:5001/history")
    print("ğŸ”§ ç³»ç»ŸçŠ¶æ€API: http://localhost:5001/system/status")
    print("\nğŸ’¡ ä½¿ç”¨æŠ€å·§:")
    print("   â€¢ é¦–æ¬¡å¯åŠ¨ä¼šé¢„è½½æ¨¡å‹ï¼Œéœ€è¦ç­‰å¾…")
    print("   â€¢ å»ºè®®å…ˆä¸Šä¼ å°æ–‡ä»¶æµ‹è¯•ç³»ç»Ÿæ€§èƒ½")
    print("   â€¢ å¯é€šè¿‡æ€§èƒ½ç›‘æ§æŸ¥çœ‹èµ„æºä½¿ç”¨æƒ…å†µ")
    print("   â€¢ ä½¿ç”¨ Ctrl+C åœæ­¢æœåŠ¡")
    print("=" * 50)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['TOKENIZERS_PARALLELISM'] = 'false'
    
    # å¯åŠ¨åº”ç”¨
    try:
        from app import app
        app.run(
            host='0.0.0.0',
            port=5001,
            debug=False,  # ç”Ÿäº§æ¨¡å¼ï¼Œæå‡æ€§èƒ½
            threaded=True,
            use_reloader=False  # ç¦ç”¨è‡ªåŠ¨é‡è½½
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æœåŠ¡å·²åœæ­¢")
        print("ğŸ’« æ„Ÿè°¢ä½¿ç”¨ OpenChemIE!")
    except Exception as e:
        print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")
        print("\nğŸ”§ æ•…éšœæ’é™¤:")
        print("   1. æ£€æŸ¥ç«¯å£5001æ˜¯å¦è¢«å ç”¨")
        print("   2. ç¡®è®¤æ‰€æœ‰ä¾èµ–åŒ…å·²æ­£ç¡®å®‰è£…")
        print("   3. æ£€æŸ¥Pythonç¯å¢ƒå’ŒCUDAé…ç½®")
        sys.exit(1)

if __name__ == '__main__':
    main() 